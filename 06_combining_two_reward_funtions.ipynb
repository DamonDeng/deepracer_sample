{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245a9cd7",
   "metadata": {},
   "source": [
    "## Combing two reward functions.\n",
    "\n",
    "In this session, we discuss the way to combine two reward functions.\n",
    "\n",
    "While training DeepRacer, it is a common scenario in which we find two interesting reward functions, and we want to make them work together as one function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eb39f9",
   "metadata": {},
   "source": [
    "Say that we want to combine the following two reward functions:\n",
    "\n",
    "1. follow the center line\n",
    "\n",
    "2. reward for faster progress\n",
    "\n",
    "The original code of these two functions are listed below.\n",
    "\n",
    "And the function names are changed to `reward_function_1` and `reward_function_2`\n",
    "\n",
    "Then we can create a new `reward_function` to call above two functions, then combine the return values together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da02f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward function 1:\n",
    "\n",
    "def reward_function_1(params):\n",
    "    '''\n",
    "    Example of rewarding the agent to follow center line\n",
    "    '''\n",
    "    \n",
    "    # Read input parameters\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "\n",
    "    # Calculate 3 markers that are increasingly further away from the center line\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    # Give higher reward if the car is closer to center line and vice versa\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 1\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "# reward function 2:\n",
    "    \n",
    "def reward_function_2(params):\n",
    "    #############################################################################\n",
    "    '''\n",
    "    Example of using steps and progress\n",
    "    '''\n",
    "\n",
    "    # Read input variable\n",
    "    steps = params['steps']\n",
    "    progress = params['progress']\n",
    "\n",
    "    # Total num of steps we want the car to finish the lap, it will vary depends on the track length\n",
    "    TOTAL_NUM_STEPS = 300\n",
    "\n",
    "    # Initialize the reward with typical value\n",
    "    reward = 1.0\n",
    "\n",
    "    # Give additional reward if the car pass every 100 steps faster than expected\n",
    "    if (steps % 100) == 0 and progress > (steps / TOTAL_NUM_STEPS) * 100 :\n",
    "        reward += 10.0\n",
    "\n",
    "    return float(reward)\n",
    "          \n",
    "def reward_function(params):\n",
    "    reward_1 = reward_function_1(params)\n",
    "    reward_2 = reward_function_2(params)\n",
    "    \n",
    "    reward = reward_1 + reward_2\n",
    "    \n",
    "    return (reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd5bb3",
   "metadata": {},
   "source": [
    "Now we can test the two reward functions seperatly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1566986",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_params = dict()\n",
    "testing_params['track_width'] = 1\n",
    "testing_params['distance_from_center'] = 0.1\n",
    "testing_params['steps'] = 100\n",
    "testing_params['progress'] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18afc6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_function_1(testing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe6fb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_function_2(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7128d3b4",
   "metadata": {},
   "source": [
    "And calling the `reward_function` give us the sum value of above two reward functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "942490f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995d7eb",
   "metadata": {},
   "source": [
    "Let's review the detail of `reward_function`, which is listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7aaf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    reward_1 = reward_function_1(params)\n",
    "    reward_2 = reward_function_2(params)\n",
    "    \n",
    "    reward = reward_1 + reward_2\n",
    "    \n",
    "    return (reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee72d9",
   "metadata": {},
   "source": [
    "In the `reward_function`, we call the `reward_function_1` and `reward_function_2`, then we add the two reward values together. While adding two rewards, we should try to keep them in same scaling order, such as keeping both of them between 0 to 1. So that both of the rewards have similar impact to over all result. \n",
    "\n",
    "In the example we used, although the `reward_function_2` returns 10, while `reward_function_1` returns 1, the combination still makes sense as `reward_function_2` reward faster racing every 100 steps.  \n",
    "\n",
    "Adding two rewards is one approach to combine them. While, in some cases, multipling them is another option.\n",
    "\n",
    "Generally speaking, if the two reward functions can work indenpently, we should add them together. On the other side, if one reward depends on other reward, we can consider multipling them.\n",
    "\n",
    "Say that we have a reward function return higher reward for higher speed. This reward funtion doesn't work independently, means that running faster is not always a good thing. We want the car to run on track at first. \n",
    "Under the premise of running on track, we hope that it can run faster.\n",
    "\n",
    "The following is a new reward_function mutipling two reward values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00de5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_speed(params):\n",
    "    reward = params['speed']\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9b5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    reward_1 = reward_function_1(params)\n",
    "    speed_reward = reward_speed(params)\n",
    "    \n",
    "    reward = reward_1 * speed_reward\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ef3e13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_params['speed'] = 1.8\n",
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7da699",
   "metadata": {},
   "source": [
    "In above code, the total reward depends on `speed reward` reward and `near to center line` reward at the same time. Some one argues that `near to center line` reward should not depend on other rewards, as running near the center line is always right, no matter it is running faster or slower.\n",
    "\n",
    "To address this, we can use adding approach and mutipling approch at the same time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9095b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    reward_1 = reward_function_1(params)\n",
    "    speed_reward = reward_speed(params)\n",
    "    \n",
    "    reward = reward_1 + reward_1 * speed_reward\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66129d8",
   "metadata": {},
   "source": [
    "While, the suggestions about adding or multipling reward are not iron rules, you can make your own decision based on your understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831339dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
