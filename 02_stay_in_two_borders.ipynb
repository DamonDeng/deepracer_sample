{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245a9cd7",
   "metadata": {},
   "source": [
    "## Default sample: Stay Inside the Two Borders in Time Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eb39f9",
   "metadata": {},
   "source": [
    "It is the second sample used in DeepRacer.\n",
    "\n",
    "The car will try to stay inside two borders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff509679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of rewarding the agent to stay inside the two borders of the track\n",
    "    '''\n",
    "    \n",
    "    # Read input parameters\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    track_width = params['track_width']\n",
    "    \n",
    "    # Give a very low reward by default\n",
    "    reward = 1e-3\n",
    "\n",
    "    # Give a high reward if no wheels go off the track and \n",
    "    # the car is somewhere in between the track borders \n",
    "    if all_wheels_on_track and (0.5*track_width - distance_from_center) >= 0.05:\n",
    "        reward = 1.0\n",
    "\n",
    "    # Always return a float value\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c3d27",
   "metadata": {},
   "source": [
    "To test the reward function, you need to setup a testing parameter.\n",
    "\n",
    "Beside \"track_width\" and \"distance_from_center\", parameter \"all_wheels_on_track\" is used, let's setup a testing parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a598ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_params = dict()\n",
    "testing_params['track_width'] = 1\n",
    "testing_params['distance_from_center'] = 0.1\n",
    "testing_params['all_wheels_on_track'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8089d7c5",
   "metadata": {},
   "source": [
    "Then, let's try the reward function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c93b270c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e708bf",
   "metadata": {},
   "source": [
    "And you can modify the testing_params to test different cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f71b2e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_params['distance_from_center'] = 100\n",
    "testing_params['all_wheels_on_track'] = False\n",
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67b276",
   "metadata": {},
   "source": [
    "Now, you can try to modify the reward_function with customized setting\n",
    "\n",
    "The following is the copy of default first cell, you can try to edit the code without worrying about making things wrong. If you screw up, just delete all the codes you write and then copy the code from the first cell again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "486b04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of rewarding the agent to stay inside the two borders of the track\n",
    "    '''\n",
    "    \n",
    "    # Read input parameters\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    track_width = params['track_width']\n",
    "    \n",
    "    # Give a very low reward by default\n",
    "    reward = 1e-3\n",
    "\n",
    "    # Give a high reward if no wheels go off the track and \n",
    "    # the car is somewhere in between the track borders \n",
    "    if all_wheels_on_track and (0.5*track_width - distance_from_center) >= 0.05:\n",
    "        reward = 1.0\n",
    "\n",
    "    # Always return a float value\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584fce8",
   "metadata": {},
   "source": [
    "After you modify the reward function, you can test it with testing-params again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19aa975f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_params['distance_from_center'] = 100\n",
    "testing_params['all_wheels_on_track'] = False\n",
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12260c",
   "metadata": {},
   "source": [
    "## Python Tips: if statement\n",
    "\n",
    "If statement is very important in program language, it gives your code the abilities to make adjustment.\n",
    "\n",
    "The following are some samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89533457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is larger than 5\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "\n",
    "if (a > 5):\n",
    "    print (\"a is larger than 5\")\n",
    "else:\n",
    "    print (\"a is smaller or equal to 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37a28b",
   "metadata": {},
   "source": [
    "And you can use `elif` when you have multiple branchs to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbeb373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is 7\n"
     ]
    }
   ],
   "source": [
    "a = 7\n",
    "\n",
    "if (a == 5):\n",
    "    print (\"a is 5\")\n",
    "elif (a == 6):\n",
    "    print (\"a is 6\")\n",
    "elif (a == 7):\n",
    "    print (\"a is 7\")\n",
    "else:\n",
    "    print (\"a is other value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf83aae",
   "metadata": {},
   "source": [
    "Please notice that `==` is used to check whether two values are equal. If you use `=`, it will set the left variable to the right value.\n",
    "\n",
    "The the following code, the value of a is set to 1:\n",
    "\n",
    "    a = 1\n",
    "    \n",
    "Operations used to check values include:\n",
    "\n",
    "    ==           equal\n",
    "    >=           larger or euqal \n",
    "    <=           smaller or equal\n",
    "    >            larger\n",
    "    <            smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c526912",
   "metadata": {},
   "source": [
    "## Python Tips: constant True and False\n",
    "\n",
    "Some parameters, some variables, are set to a boolean value, which only contains two possible value: True or False, like \"all_wheels_on_track\"\n",
    "\n",
    "Boolean value can be used directly in `if` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1dd8ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love coding\n"
     ]
    }
   ],
   "source": [
    "love_coding = True\n",
    "\n",
    "if (love_coding):\n",
    "    print (\"I love coding\")\n",
    "else:\n",
    "    print (\"er....., I am not sure about that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a3fa265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "er....., I am not sure about that\n"
     ]
    }
   ],
   "source": [
    "love_coding = False\n",
    "\n",
    "if (love_coding):\n",
    "    print (\"I love coding\")\n",
    "else:\n",
    "    print (\"er....., I am not sure about that\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018a651",
   "metadata": {},
   "source": [
    "## Python Tips: Multiple conditions\n",
    "\n",
    "If you want to combine multiple conditions, you can use `or`, `and`, `not`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86a9ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You don't love coding and working at the same time\n"
     ]
    }
   ],
   "source": [
    "love_coding = False\n",
    "love_working = True\n",
    "\n",
    "if (love_coding and love_working):\n",
    "    print ('Good programmer')\n",
    "else:\n",
    "    print ('You don\\'t love coding and working at the same time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183702fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you love coding or you love working\n"
     ]
    }
   ],
   "source": [
    "if (love_coding or love_working):\n",
    "    print ('you love coding or you love working')\n",
    "else:\n",
    "    print ('You don\\'t love coding , neither do you love working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af688dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbbd5d36",
   "metadata": {},
   "source": [
    "## Configs and result\n",
    "\n",
    "If your model has good potential, but the training is stop because of time limitation. Then you way want to train the model again. In this case, you don't need to train the model from the begining, you can clone the model and start the new training with the best checkpoint of your old one.\n",
    "\n",
    "While training the `stay in two borders` model, we got the following result in the first 1 hour. It is obvious that the result is not good enough, but the trend is good enough to make us believe that there will be a better model if we have more time to train it. \n",
    "\n",
    "<img src=\"./images/02_result.png\" width = \"300\"  alt=\"result\"  />\n",
    "\n",
    "Then we clone the first model and train it again. In the next hour, we got the following metrics, which reachs 100% progress in evaluation:\n",
    "\n",
    "<img src=\"./images/02_result_clone.png\" width = \"300\"  alt=\"result\"  />\n",
    "\n",
    "And the evaluation results are listed below.\n",
    "\n",
    "The model finished two evaluations without going out of track, and the time used to finish one lap is about 11 to 12 seconds, which is much better than the first model.\n",
    "\n",
    "By submitting the model to community race, we got a result of 36 seconds for 3 laps\n",
    "\n",
    "<img src=\"./images/02_evaluation.png\" width = \"300\"  alt=\"evaluation\"  />\n",
    "\n",
    "\n",
    "Action space and other hyper parameters are listed as below.\n",
    "\n",
    "Please be notice that the speed was set to 1 to 2 meters per second. It is one of the key settings to make the model reach 12 seconds per lap.\n",
    "\n",
    "<img src=\"./images/02_action_space.png\" width = \"300\"  alt=\"action space\"  />\n",
    "\n",
    "<img src=\"./images/02_hyper_parameters.png\" width = \"300\"  alt=\"hyper parameters\"  />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf417a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
