{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245a9cd7",
   "metadata": {},
   "source": [
    "## Default sample: Follow the Center Line in Time Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eb39f9",
   "metadata": {},
   "source": [
    "It is the default sample used in DeepRacer.\n",
    "\n",
    "The car will try to follow the center line of track.\n",
    "\n",
    "There are markers defined in the code:\n",
    "\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "    \n",
    "The reward will be caculated base on whether distance_from_center is smaller than these markers.\n",
    "\n",
    "You can try to modify the markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff509679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of rewarding the agent to follow center line\n",
    "    '''\n",
    "    \n",
    "    # Read input parameters\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "\n",
    "    # Calculate 3 markers that are increasingly further away from the center line\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    # Give higher reward if the car is closer to center line and vice versa\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 1\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c3d27",
   "metadata": {},
   "source": [
    "To test the reward function, you need to setup a testing parameter.\n",
    "\n",
    "As only \"track_width\" and \"distance_from_center\" are used, let's setup a testing parameter with these two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a598ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_params = dict()\n",
    "testing_params['track_width'] = 1\n",
    "testing_params['distance_from_center'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8089d7c5",
   "metadata": {},
   "source": [
    "Then, let's try the reward function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93b270c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e708bf",
   "metadata": {},
   "source": [
    "And you can modify the testing_params to test different cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71b2e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_params['distance_from_center'] = 100\n",
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83c7845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_params['distance_from_center'] = 0.001\n",
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67b276",
   "metadata": {},
   "source": [
    "Now, you can try to modify the reward_function with customized marker or customized reward.\n",
    "\n",
    "The following is the copy of default reward_function, you can try to edit the code without worrying about making things wrong. If you screw up, just delete all the codes you write and then copy the code from the first cell again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486b04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of rewarding the agent to follow center line\n",
    "    '''\n",
    "    \n",
    "    # Read input parameters\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "\n",
    "    # Calculate 3 markers that are increasingly further away from the center line\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    # Give higher reward if the car is closer to center line and vice versa\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 1\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584fce8",
   "metadata": {},
   "source": [
    "After you modify the reward function, you can test it with testing-params again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19aa975f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_params['distance_from_center'] = 100\n",
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a4125",
   "metadata": {},
   "source": [
    "In the following cells, there are several common grammar error in Python.\n",
    "\n",
    "They are listed here for your reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12260c",
   "metadata": {},
   "source": [
    "## Python Tips: Indent issus\n",
    "\n",
    "Python parses the code with indent, all the codes on same level should have same indent.\n",
    "\n",
    "In the following code, `a = 1` and `b = 2` belong to function named \"reward_function\", so they should have same indent like:\n",
    "\n",
    "    def reward_function(params):\n",
    "        a = 1\n",
    "        b = 2  \n",
    "        \n",
    "The following codes are incorrect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89533457",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    b = 2\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def reward_function(params):\n",
    "    a = 1\n",
    "  b = 2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7659e79",
   "metadata": {},
   "source": [
    "The following codes are right in grammar, but they may not work as you expected.\n",
    "\n",
    "In the code, `b = 2` is not belong to \"reward_function\", as it has same indent with \"reward_function\". It is on the same level of \"reward_function\", it is not belong to \"reward_function\". That means you can not use variable `b` in \"reward_function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dca9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    a = 1\n",
    "b = 2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545a8a7",
   "metadata": {},
   "source": [
    "If you use `if` statement in the code, make sure that the codes belong to those `if` statement have right indent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0228967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    a = 1 # these are some codes you write\n",
    "    b = 2\n",
    "    \n",
    "    if (params['distance_from_center'] > 10):\n",
    "        print (\"larger than 10\")\n",
    "    else:\n",
    "        print (\"smaller or equal to 10\")\n",
    "        \n",
    "    c = 3 # these are some other codes not belong to if statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee621b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "larger than 10\n"
     ]
    }
   ],
   "source": [
    "testing_params['distance_from_center'] = 100\n",
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e8187",
   "metadata": {},
   "source": [
    "### return statement in function\n",
    "\n",
    "Be notice that a function ends at the `return`, codes belong to the function but are after `return` will not be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1dd8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    print ('this code will be run')\n",
    "    return (0.1)\n",
    "    print ('this code will not be run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbe8fdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this code will be run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_params = dict()\n",
    "reward_function(testing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12df2c2",
   "metadata": {},
   "source": [
    "## Configs and result\n",
    "\n",
    "To train a good model, we can tune the hyper parameters including action space and other training parameters like learning rate, batch size, etc.\n",
    "\n",
    "If you are training your first model, it is recommended to use the default setting.\n",
    "\n",
    "The following chart is the training metrics of the `follow the center line` model with default settings:\n",
    "\n",
    "The Gree line is the averate reward, the Blue line is the finish rate of training, and the Red line is the finish rate of evalution:\n",
    "\n",
    "<img src=\"./images/01_result.png\" width = \"300\"  alt=\"result\"  />\n",
    "\n",
    "\n",
    "\n",
    "And the evaluation results are listed below.\n",
    "\n",
    "<img src=\"./images/01_evaluation.png\" width = \"300\"  alt=\"evaluation\"  />\n",
    "\n",
    "\n",
    "Action space and other hyper parameters are listed as below:\n",
    "\n",
    "<img src=\"./images/01_action_space.png\" width = \"300\"  alt=\"action space\"  />\n",
    "\n",
    "<img src=\"./images/01_hyper_parameters.png\" width = \"300\"  alt=\"hyper parameters\"  />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822121a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc77b032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e8eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
